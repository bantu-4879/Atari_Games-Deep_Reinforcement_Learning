{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make('Pong-v4')\n",
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space Shape\", env.observation_space.shape)\n",
    "\n",
    "# Reset the environment\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "env = make_vec_env('Pong-v4', n_envs=4)\n",
    "\n",
    "# Initialize the model\n",
    "model = PPO(policy = \"CnnPolicy\",\n",
    "            env = env,\n",
    "            batch_size = 128,\n",
    "            clip_range = 0.1,\n",
    "            ent_coef = 0.01,\n",
    "            gae_lambda = 0.9,\n",
    "            gamma = 0.99,\n",
    "            learning_rate = 0.0001,\n",
    "            max_grad_norm = 0.5,\n",
    "            n_epochs = 4,\n",
    "            n_steps = 256,\n",
    "            vf_coef = 0.5,\n",
    "            verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=int(1e8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"ppo-pong-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "mean_reward, std_reward =  evaluate_policy(model, env, n_eval_episodes=25)\n",
    "print('Mean Reward :', mean_reward)\n",
    "print('Deviation :', std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "\n",
    "env_id = \"Pong-v4\"\n",
    "video_folder = \"./videos/\"\n",
    "video_length = 1500\n",
    "\n",
    "vec_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
    "\n",
    "obs = vec_env.reset()\n",
    "\n",
    "# Record the video starting at the first step\n",
    "vec_env = VecVideoRecorder(vec_env, video_folder,\n",
    "                       record_video_trigger=lambda x: x == 0, video_length=video_length,\n",
    "                       name_prefix=f\"random-agent-{env_id}-1\")\n",
    "\n",
    "vec_env.reset()\n",
    "for i in range(video_length + 1):\n",
    "  action, _states = model.predict(obs, deterministic=True)\n",
    "  obs, rewards, dones, info = vec_env.step(action)\n",
    "  \n",
    "# Save the video\n",
    "vec_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
